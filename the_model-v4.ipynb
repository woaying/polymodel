{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211721c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d070f514",
   "metadata": {},
   "source": [
    "# part 1. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "educated-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy.stats import norm\n",
    "from sklearn import base\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8504b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processIndex(df):\n",
    "    try:\n",
    "        df.index=pd.to_datetime(df.index)\n",
    "    except TypeError:\n",
    "        raise TypeError('Incorrect index')\n",
    "    if df.index[0]<datetime.date(2000,1,1):\n",
    "        raise ValueError('Index not in correct range')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "received-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all files:\n",
    "path1='/Users/yingzhang/Documents/project/Poly_models/ETF_daily.csv'\n",
    "path2='/Users/yingzhang/Documents/project/Poly_models/ETF_weekly.csv'\n",
    "path3='/Users/yingzhang/Documents/project/Poly_models/ETF_biweekly.csv'\n",
    "path4='/Users/yingzhang/Documents/project/Poly_models/ETF_monthly.csv'\n",
    "ETF_daily=processIndex(pd.read_csv(path1, index_col=0))\n",
    "ETF_weekly=processIndex(pd.read_csv(path2, index_col=0))\n",
    "ETF_biweekly=processIndex(pd.read_csv(path3, index_col=0))\n",
    "ETF_monthly=processIndex(pd.read_csv(path4, index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "persistent-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all files:\n",
    "path_1='/Users/yingzhang/Documents/project/Poly_models/stock_daily.csv'\n",
    "path_2='/Users/yingzhang/Documents/project/Poly_models/stock_weekly.csv'\n",
    "path_3='/Users/yingzhang/Documents/project/Poly_models/stock_biweekly.csv'\n",
    "path_4='/Users/yingzhang/Documents/project/Poly_models/stock_monthly.csv'\n",
    "stock_daily=processIndex(pd.read_csv(path_1, index_col=0))\n",
    "stock_weekly=processIndex(pd.read_csv(path_2, index_col=0))\n",
    "stock_biweekly=processIndex(pd.read_csv(path_3, index_col=0))\n",
    "stock_monthly=processIndex(pd.read_csv(path_4, index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1026b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stock prices for sharpe ratio:\n",
    "file_path='/Users/yingzhang/Documents/project/Poly_models/stocks_adjclose_855_fixed.csv'\n",
    "stock_price=processIndex(pd.read_csv(file_path,index_col=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bdd066",
   "metadata": {},
   "source": [
    "### Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opposite-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETF_data_list=[ETF_daily, ETF_weekly, ETF_biweekly, ETF_monthly]\n",
    "stock_data_list=[stock_daily, stock_weekly, stock_biweekly, stock_monthly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88768b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list_for_rolling_2years=[datetime.date(i,j,1) for i in range(2019,2021) for j in range(1,13)]+[datetime.date(2021,1,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbeb7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstday=stock_daily.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "136ce390",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateformat='%Y-%m-%d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "958c41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# month_list_for_rolling=[datetime.date(i,j,1).strftime(dateformat) for i in range(2011,2021) for j in range(1,13)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b913a",
   "metadata": {},
   "source": [
    "# part 2. get return list for specific time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9339c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submonth(end_date, n_of_month=12):\n",
    "    return end_date-relativedelta(months=n_of_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "reasonable-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addmonth(start_date, n_of_month=12):\n",
    "    return start_date+relativedelta(months=n_of_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "declared-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectMonth(start_date, end_date, dataframe):\n",
    "# # dataframe should have index as \"2021-01-01\"\n",
    "#     dateformat='%Y-%m-%d'\n",
    "    start=start_date.strftime(dateformat)\n",
    "    end=end_date.strftime(dateformat)\n",
    "    return dataframe.loc[(dataframe.index>=start) & (dataframe.index<end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c3d0c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnList(start_date,end_date,list_of_dataframe):\n",
    "    '''\n",
    "    getting the required month from a list of dateframe and concatenate them in one dataFrame\n",
    "    Eg: put together all selected months data of daily, weekly, biweekly, monthly return\n",
    "    \n",
    "    '''\n",
    "    alist=[]\n",
    "    for df in list_of_dataframe:\n",
    "        alist.append(selectMonth(start_date, end_date, df))\n",
    "    return pd.concat(alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8403555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanUp(dataframe):\n",
    "    null_cols=dataframe.columns[dataframe.isnull().any()]\n",
    "    return dataframe.drop(null_cols,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505ebe6",
   "metadata": {},
   "source": [
    "# part 3. percentiles, basefunctions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d897fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pctlList(dataframe,pctl=['50','25','75']):\n",
    "    '''gives the percentiles of the dateframe of those pctl'''\n",
    "    df=pd.DataFrame(columns=dataframe.columns) \n",
    "    for k in pctl:\n",
    "        if k=='1':\n",
    "            df.loc[k+'_percentile']=[pareto_CVaR(dataframe[i],0.025) for i in dataframe.columns]\n",
    "        elif k=='99':\n",
    "            df.loc[k+'_percentile']=[pareto_CVaR(dataframe[i],0.975) for i in dataframe.columns]\n",
    "        else:\n",
    "            df.loc[k+'_percentile']=[np.percentile(dataframe[i].dropna(),int(k)) for i in dataframe.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd3d66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basefunc(df,dataframe=None):\n",
    "    '''getting the basefunc function of two dataframe.\n",
    "       df is used to get the pctl, dataframe is the X.\n",
    "       function pctlList required!\n",
    "       drop columns with null value\n",
    "       output of this function is a dataframe with each col containing tuple (1, phi1, phi2, phi3, phi4)\n",
    "    '''\n",
    "    if dataframe is None:\n",
    "        dataframe=df\n",
    "    \n",
    "    df_pctl=pctlList(df) # calculate percentiles\n",
    "    \n",
    "    # calculate base functions\n",
    "    phi1=dataframe\n",
    "    phi2=abs(dataframe-df_pctl.loc['50_percentile'])\n",
    "    phi3=1/2*(abs(dataframe-df_pctl.loc['75_percentile'])\n",
    "         -abs(dataframe-df_pctl.loc['25_percentile'])\n",
    "         -df_pctl.loc['75_percentile']-df_pctl.loc['25_percentile'])+dataframe\n",
    "    phi4=1/2*(abs(dataframe-df_pctl.loc['75_percentile'])\n",
    "         +abs(dataframe-df_pctl.loc['25_percentile'])\n",
    "         -df_pctl.loc['75_percentile']+df_pctl.loc['25_percentile'])\n",
    "    \n",
    "    # put base funcs in list and form a new df\n",
    "    base_df=pd.DataFrame(columns=dataframe.columns,index=dataframe.index)\n",
    "    for col in dataframe.columns:\n",
    "        base_df[col]=list(zip(list(phi1[col]),list(phi2[col]),list(phi3[col]),list(phi4[col])))\n",
    "    return base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6207947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class basefuncTransformer(base.BaseEstimator, base.TransformerMixin): \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return basefunc(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2271bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLRestimator(base.BaseEstimator, base.RegressorMixin):\n",
    "    \n",
    "    def __init__(self, estimator_factory):\n",
    "        # estimator_factory can be called to produce estimators\n",
    "        self.estimator_factory=estimator_factory       \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Create an estimator and fit it with the portion in each group\n",
    "        self.estimators_={}\n",
    "        for column in X.columns:\n",
    "            if np.ndim(list(X[column]))>1:\n",
    "                temp=list(X[column])\n",
    "            else:\n",
    "                temp=np.transpose([list(X[column])])\n",
    "            self.estimators_[column]=self.estimator_factory().fit(temp,list(y))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Call the appropriate predict method for each row of X\n",
    "        result=pd.DataFrame(columns=X.columns,index=X.index)\n",
    "        for column in X.columns:\n",
    "            temp=self.estimators_[column].predict(list(X[column]))\n",
    "            result[column]=temp\n",
    "        return result    \n",
    "\n",
    "    def residuals(self, X, y):\n",
    "        result=self.predict(X)\n",
    "        return result.sub(y,axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8306a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto_CVaR(dataserie, qtl, prop=0.1, NumSigma=0, skip=2, origin=0):\n",
    "    dataserie=dataserie.dropna()\n",
    "    ds_sorted=list(dataserie.sort_values())\n",
    "\n",
    "    if qtl<0.5:\n",
    "        side=-1\n",
    "    elif qtl>0.5:\n",
    "        side=1\n",
    "        qtl=1-qtl\n",
    "    else:\n",
    "        return np.median(df_sorted)    \n",
    "\n",
    "#     if prop==None:\n",
    "#         prop=qtl\n",
    "    \n",
    "    n=len(dataserie)\n",
    "    nprop=int(round(n*prop))\n",
    "    \n",
    "#     if origin==None:\n",
    "#         origin=0\n",
    "#     else:\n",
    "#         origin=np.median(df_sorted)\n",
    "         \n",
    "    if side==-1:\n",
    "        tail=np.array(ds_sorted[skip:nprop+skip])\n",
    "    elif side==1:\n",
    "        tail=np.array(ds_sorted[n-nprop-skip:n-skip][::-1]) # need to be decreasing for same y_label\n",
    "       \n",
    "    log_tail=np.log(abs(tail-origin))\n",
    "    y_label=[-np.log(i+1+skip)-(n-(i+1+skip))/2/n for i in range(nprop)]\n",
    "\n",
    "    x_data=np.transpose([log_tail])\n",
    "    lr=LinearRegression()\n",
    "    lr.fit(x_data, y_label)\n",
    "        \n",
    "    hill11=lr.coef_[0]\n",
    "    hill21=np.exp(-(lr.intercept_+np.log(n))/hill11)\n",
    "    hill31=origin\n",
    "    \n",
    "    ParetoCVaR= hill31 + side * hill21 * hill11 / (hill11 - 1) * qtl ** (-1 / hill11)\n",
    "    return ParetoCVaR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-extra",
   "metadata": {},
   "source": [
    "# part 4.  cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6ce9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firstdateHandle(date):\n",
    "    if date.day<5:\n",
    "        d=datetime.date(date.year,date.month,1)\n",
    "    elif (date.month!=2 and date.day>27) or (date.month==2 and date.day>25):\n",
    "        d=date\n",
    "    else:\n",
    "        raise ValueError('ValueError: dataframe start date incorrect')    \n",
    "    return d\n",
    "\n",
    "def lastdateHandle(date):\n",
    "    if date.day<5:\n",
    "        d=date\n",
    "    elif (date.month!=2 and date.day>27) or (date.month==2 and date.day>25):\n",
    "        tempdate=addmonth(date,1)\n",
    "        d=datetime.date(tempdate.year,tempdate.month,1)   \n",
    "    else:\n",
    "        raise ValueError('ValueError: dataframe last date incorrect')   \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92f55062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2021, 7, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastdateHandle(datetime.date(2021,6,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d7cd3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "end=month_list_for_rolling_2years[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7243bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=submonth(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09ae98bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ETF_data=cleanUp(returnList(start,end,ETF_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd8754ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-03-01', '2018-03-02', '2018-03-02', '2018-03-02',\n",
       "               '2018-03-05', '2018-03-06', '2018-03-07', '2018-03-08',\n",
       "               '2018-03-09', '2018-03-09',\n",
       "               ...\n",
       "               '2019-02-20', '2019-02-21', '2019-02-22', '2019-02-22',\n",
       "               '2019-02-22', '2019-02-25', '2019-02-26', '2019-02-27',\n",
       "               '2019-02-28', '2019-02-28'],\n",
       "              dtype='datetime64[ns]', length=367, freq=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETF_data.index.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "yellow-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dltMonthSplit(n, dataframe):\n",
    "    '''\n",
    "    remove rows of the nth month in the dataframe\n",
    "    n should be within the range of n_of_month as in func selectMonth\n",
    "    Output should be two dataframes:\n",
    "    1. removed month sub_df and 2. leftover_df\n",
    "    '''\n",
    "    \n",
    "    first_index=dataframe.index.sort_values()[0] # '2011-02-01'\n",
    "    last_index=dataframe.index.sort_values()[-1] # '2012-01-31'\n",
    "    first_date=firstdateHandle(first_index) # datetime.datetime(2011, 2, 1, 0, 0)\n",
    "    last_date=lastdateHandle(last_index)\n",
    "    \n",
    "    # here n_of_month is 12 between ('2011-02-01', '2012-01-31')\n",
    "    n_of_month=(last_date.year-first_date.year)*12+(last_date.month-first_date.month)\n",
    "    first=datetime.date(first_date.year,first_date.month,1)\n",
    "    month_list=[addmonth(first,i) for i in range(n_of_month)]\n",
    "    \n",
    "    if n>(n_of_month) or n<1:\n",
    "        raise ValueError('nth month selected is out of range of the total number of months in dataframe') \n",
    "    elif isinstance(n,(float,str,bool)):\n",
    "        raise TypeError('data type wrong for n')\n",
    "    else:\n",
    "        start=month_list[n-1]\n",
    "        end=addmonth(start,1).strftime(dateformat)\n",
    "        start=start.strftime(dateformat)\n",
    "        dltMonth_df=dataframe.iloc[(dataframe.index>=start) & (dataframe.index<end)]\n",
    "        lftMonth_df=dataframe.iloc[(dataframe.index<start) | (dataframe.index>=end)]\n",
    "    return [dltMonth_df,lftMonth_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d609c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CrossValidation(basefunc_df, stock_list, number_of_month=12, estimator=LinearRegression): \n",
    "    '''\n",
    "    number_of_month=12 for 1 year data\n",
    "    factor_df should be the base_func.\n",
    "    '''\n",
    "    lre=MLRestimator(estimator)\n",
    "    residuals=pd.DataFrame(columns=basefunc_df.columns)\n",
    "    \n",
    "    for i in range(1,number_of_month+1):\n",
    "        [X_dlt_data,X_lft_data]=dltMonthSplit(i,basefunc_df)\n",
    "        [y_dlt_data,y_lft_data]=dltMonthSplit(i,stock_list)\n",
    "        lre.fit(X_lft_data,y_lft_data)\n",
    "        pred=lre.predict(X_dlt_data)\n",
    "        resSqr=pred.sub(y_dlt_data,axis='index')**2\n",
    "        residuals.loc[str(i)+'_month_removed']=resSqr.sum()\n",
    "    \n",
    "    stock_sumsqr=sum(stock_list**2)\n",
    "    temp=stock_sumsqr/residuals.sum()-1\n",
    "    temp[temp<0]=0\n",
    "    scores=np.sqrt(temp)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a163951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorSelect(scores, basefunc):\n",
    "    max_col=scores.idxmax()\n",
    "    max_score=max(scores)\n",
    "    scores_selected=scores[scores>max(scores)/2]\n",
    "    return scores_selected.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48153f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVSelectTransformer(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self, y, estimator=LinearRegression):\n",
    "        self.estimator=estimator\n",
    "        self.y=y\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def _all_scores_(self, X):\n",
    "        return CrossValidation(X, self.y, 12, self.estimator)\n",
    "\n",
    "    def _selected_columns_(self, X):\n",
    "        scores=self._all_scores_(X)\n",
    "        return factorSelect(scores, X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[self._selected_columns_(X)]\n",
    "     \n",
    "    def scores_(self, X):\n",
    "        scores=self._all_scores_(X)\n",
    "        columns=self._selected_columns_(X)\n",
    "        return scores[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8641d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyModelEstimator(base.BaseEstimator, base.RegressorMixin):\n",
    "    \n",
    "    def __init__(self, y, bsf=basefuncTransformer, fs=CVSelectTransformer, es=MLRestimator):\n",
    "        self.y=y\n",
    "        self.bsf=bsf()\n",
    "        self.fs=fs(self.y)\n",
    "        self.es=es(LinearRegression)\n",
    "        self.base=pd.DataFrame()\n",
    "        self.X_data=pd.DataFrame()\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.base=self.bsf.fit_transform(X)\n",
    "        self.X_data=self.fs.fit_transform(self.base)\n",
    "        self.es=self.es.fit(self.X_data, self.y)\n",
    "        return self\n",
    "    \n",
    "    def scores_(self, X):\n",
    "        return self.fs.scores_(self.base)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        base=self.bsf.fit_transform(X)\n",
    "        X_data=self.fs.fit_transform(base)\n",
    "        return self.es.predict(X_data)\n",
    "    \n",
    "    def residuals(self, X):\n",
    "        y_pred=self.predict(X)\n",
    "        return y_pred.sub(self.y, axis='index')      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3ac22c",
   "metadata": {},
   "source": [
    "<span style=\"color:RED\">PAY ATTENTION: parameter of PolyModelEstimator has to be the same as the y put into fit!</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8813fd8b",
   "metadata": {},
   "source": [
    "# part 5. stress VaR and long-term expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5050d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicators(df,df_long,y):\n",
    "    pme=PolyModelEstimator(y)\n",
    "    pme.fit(df)\n",
    "    scores=pme.scores_(df)\n",
    "    residuals=pme.residuals(df)\n",
    "    estimators=pme.es.estimators_\n",
    "    selected_col=list(estimators.keys())\n",
    "    \n",
    "    if selected_col==[]:\n",
    "        return y.name\n",
    "    \n",
    "    df=df[selected_col]\n",
    "    df_long=df_long[selected_col]\n",
    "    \n",
    "    pctl_long=['1']+[str(i) for i in range(5,100,5)]+['99']\n",
    "    df_long_pctl=pctlList(df_long, pctl_long)\n",
    "    basefunc_longterm=basefunc(df, df_long_pctl)\n",
    "    \n",
    "    temp=pd.DataFrame(index=df_long_pctl.index)\n",
    "    for i in selected_col:\n",
    "        temp[i]=np.matmul(np.array(list(basefunc_longterm[i])),estimators[i].coef_)+estimators[i].intercept_\n",
    "    \n",
    "    weight=[0.025]+[0.05 for _ in range(5,100,5)]+[0.025]\n",
    "    miu=norm.ppf(.99)\n",
    "    ltExpect=pd.Series(np.matmul(weight, temp.values),index=selected_col)\n",
    "    temp=pd.DataFrame.min(temp)\n",
    "    stressVaR=np.sqrt(temp**2+miu**2*np.var(residuals))\n",
    "    max_sVaR=max(stressVaR)\n",
    "    \n",
    "    # longterm expectation\n",
    "    L=sum(scores*ltExpect)/sum(scores)\n",
    "    kappa=0.01\n",
    "    # utility\n",
    "    U=L-kappa*max_sVaR\n",
    "    \n",
    "    return [L, max_sVaR, U]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9925d",
   "metadata": {},
   "source": [
    "# part 6. for all stock_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33779167",
   "metadata": {},
   "source": [
    "1. run for two years: 12-31-2018 to 12-31-2020\n",
    "2. change the selectdate\n",
    "3. long_term_data start from 1-3-2011 ends the same date as ETF_data\n",
    "4. thinking about the pyspark distribution\n",
    "5. thinking about keeping basefunc for all stocks\n",
    "6. performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbb228f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "end=month_list_for_rolling_2years[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "404f81ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=submonth(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89355bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2018, 1, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56c9182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_for_sp=stock_price[stock_price.index<=start.strftime(dateformat)].index[-1]\n",
    "end_for_sp=stock_price[stock_price.index<=end.strftime(dateformat)].index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fc76b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-12-31 00:00:00')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_for_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccdb9b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_before=stock_price.loc[start_for_sp]\n",
    "stock_now=stock_price.loc[end_for_sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a12a22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainfunc(ETF_data_list, stock_data_list, stock_price, month_list_for_rolling, firstday=firstday):\n",
    "    for i in month_list_for_rolling:\n",
    "        end_date=i\n",
    "        start_date=submonth(end_date)\n",
    "        \n",
    "        fields=['Stock','L', 'Max_sVaR', 'U','Sharpe','Stock_price_1year_before',\n",
    "                'Stock_price_now','Stock_r','Std_of_returns']\n",
    "        filename='indicators'+end_date.strftime(dateformat)+'.csv'\n",
    "        filename_zeroscores='zero_scores_stocks.csv'\n",
    "        \n",
    "        ETF_data=cleanUp(returnList(start_date,end_date,ETF_data_list))\n",
    "        ETF_long_term_data=returnList(firstday,end_date,ETF_data_list)\n",
    "        stock_data=cleanUp(returnList(start_date,end_date,stock_data_list))\n",
    "        stock_daily=cleanUp(selectMonth(start_date,end_date,stock_data_list[0]))\n",
    "        \n",
    "        #choose the last date for the split of start point to ensure we are using the previous price for S(t-1year)\n",
    "        start_for_sp=stock_price[stock_price.index<=start_date.strftime(dateformat)].index[-1]\n",
    "        end_for_sp=stock_price[stock_price.index<=end_date.strftime(dateformat)].index[-1]\n",
    "        stock_before=stock_price.loc[start_for_sp]\n",
    "        stock_now=stock_price.loc[end_for_sp]\n",
    "        stock_r=stock_price.loc[end_for_sp]/stock_price.loc[start_for_sp]-1\n",
    "        \n",
    "        mydict=[]\n",
    "        for stock in stock_data.columns:\n",
    "            sp_before=stock_before[stock]\n",
    "            sp_now=stock_now[stock]\n",
    "            r=stock_r[stock]\n",
    "            sigma=stock_daily[stock].std()\n",
    "            sharpe=r/sigma\n",
    "            temp=indicators(ETF_data, ETF_long_term_data, stock_data[stock])\n",
    "            \n",
    "            if isinstance(temp,str):\n",
    "                with open(filename_zeroscores,'a') as f:\n",
    "                    writer = csv.DictWriter(f,fieldnames=['end_date', 'stock'])\n",
    "                    writer.writerows([{'end_date':end_date.strftime(dateformat), 'stock':temp}])\n",
    "            else:\n",
    "                [L,max_sVaR,U]=temp\n",
    "                row={'Stock':stock,'L':L,'Max_sVaR':max_sVaR,'U':U,'Sharpe':sharpe,\n",
    "                     'Stock_price_1year_before':sp_before,'Stock_price_now':sp_now,'Stock_r':r,\n",
    "                     'Std_of_returns':sigma}\n",
    "                mydict.append(row)\n",
    "#                 print(row)\n",
    "        \n",
    "        with open(filename, 'w') as csvfile: \n",
    "            writer = csv.DictWriter(csvfile, fieldnames = fields) \n",
    "            writer.writeheader() \n",
    "            writer.writerows(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffb1ac7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2019, 8, 1),\n",
       " datetime.date(2019, 9, 1),\n",
       " datetime.date(2019, 10, 1),\n",
       " datetime.date(2019, 11, 1),\n",
       " datetime.date(2019, 12, 1),\n",
       " datetime.date(2020, 1, 1),\n",
       " datetime.date(2020, 2, 1),\n",
       " datetime.date(2020, 3, 1),\n",
       " datetime.date(2020, 4, 1),\n",
       " datetime.date(2020, 5, 1),\n",
       " datetime.date(2020, 6, 1),\n",
       " datetime.date(2020, 7, 1),\n",
       " datetime.date(2020, 8, 1),\n",
       " datetime.date(2020, 9, 1),\n",
       " datetime.date(2020, 10, 1),\n",
       " datetime.date(2020, 11, 1),\n",
       " datetime.date(2020, 12, 1),\n",
       " datetime.date(2021, 1, 1)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_list_for_rolling_2years[7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e23fdf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 106557.55431509018\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# starting time\n",
    "start_time = time.time()\n",
    "\n",
    "# program body starts\n",
    "mainfunc(ETF_data_list, stock_data_list, stock_price, month_list_for_rolling_2years[7:])\n",
    "\n",
    "# sleeping for 1 sec to get 10 sec runtime\n",
    "# time.sleep(1)\n",
    "\n",
    "# program body ends\n",
    "\n",
    "# end time\n",
    "end_time = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end_time - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2923b616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5091666666666665"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5433/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3f09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b112a2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
